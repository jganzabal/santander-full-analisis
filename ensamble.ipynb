{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Activation, BatchNormalization, Dropout, Lambda, Input\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.optimizers import adam\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from matplotlib import pyplot as plt\n",
    "from lightgbm.basic import Booster\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from NaiveBayesPDF import NaiveBayesPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargo datos train y valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train_splitted.csv')\n",
    "df_valid = pd.read_csv('data/valid_splitted.csv')\n",
    "\n",
    "X_train = df_train.drop(columns=['ID_code', 'target'])\n",
    "X_valid = df_valid.drop(columns=['ID_code', 'target'])\n",
    "\n",
    "y_train = df_train['target']\n",
    "y_valid = df_valid['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = np.array([y_train, 1-y_train]).T\n",
    "y_valid_cat = np.array([y_valid, 1-y_valid]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160000,), (160000, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_train_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_NB = pickle.load(open('trained_models/GNB_train_only.pk', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_MLP_Keras_0 = load_model('trained_models/MLP_keras_balanced_0.h5')\n",
    "model_MLP_Keras_1 = load_model('trained_models/MLP_keras_balanced_1.h5')\n",
    "# model_MLP_Keras_2 = load_model('trained_models/MLP_keras_balanced_2.h5')\n",
    "# model_MLP_Keras_3 = load_model('trained_models/MLP_keras_balanced_3.h5')\n",
    "# model_MLP_Keras_4 = load_model('trained_models/MLP_keras_balanced_4.h5')\n",
    "# model_MLP_Keras_5 = load_model('trained_models/MLP_keras_balanced_5.h5')\n",
    "# model_MLP_Keras_6 = load_model('trained_models/MLP_keras_balanced_6.h5')\n",
    "# model_MLP_Keras_7 = load_model('trained_models/MLP_keras_balanced_7.h5')\n",
    "# model_MLP_Keras_8 = load_model('trained_models/MLP_keras_balanced_8.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LGBM = pickle.load(open('trained_models/lgmb_model_train_only.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_NBpdf = pickle.load(open('trained_models/naive_bayes_pdf_train_only.pk', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(models, data, y=None):\n",
    "    predictions = []\n",
    "    scores = []\n",
    "    aucs = []\n",
    "    accs = []\n",
    "    for model in models:\n",
    "        if type(model) == GaussianNB:\n",
    "            print('Predicting Naive Bayes...')\n",
    "            # acc = model.score(data, y)\n",
    "            model_pred = model.predict_proba(data)[:,1]\n",
    "        if type(model) == Sequential:\n",
    "            print('Predicting Keras MLP...')\n",
    "            # acc = model.evaluate(data, y)\n",
    "            model_pred = model.predict(data, verbose=1)[:,0]\n",
    "        if type(model) == Booster:\n",
    "            print('Predicting LGBM...')\n",
    "            model_pred = model.predict(data)\n",
    "        if type(model) == NaiveBayesPDF:\n",
    "            print('Predicting NBpdf...')\n",
    "            _, _, _, _, model_pred, _, _ = model.predict(data.values)\n",
    "        if y is not None:\n",
    "            aucs.append(roc_auc_score(y, model_pred))\n",
    "            accs.append(((model_pred>0.5)==y).sum()/len(y))\n",
    "        predictions.append(model_pred)\n",
    "        #predictions.append(np.log(model_pred/(1-model_pred)))\n",
    "    return np.array(predictions).T, aucs, accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    model_NB, model_NBpdf, model_LGBM,\n",
    "    model_MLP_Keras_0,\n",
    "    model_MLP_Keras_1,\n",
    "#     model_MLP_Keras_2,\n",
    "#     model_MLP_Keras_3,\n",
    "#     model_MLP_Keras_4,\n",
    "#     model_MLP_Keras_5,\n",
    "#     model_MLP_Keras_6,\n",
    "#     model_MLP_Keras_7,\n",
    "#     model_MLP_Keras_8,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Naive Bayes...\n",
      "Predicting NBpdf...\n",
      "Predicting LGBM...\n",
      "Predicting Keras MLP...\n",
      "160000/160000 [==============================] - 2s 14us/step\n",
      "Predicting Keras MLP...\n",
      "160000/160000 [==============================] - 2s 13us/step\n",
      "[0.8893228519335807, 0.9049951884982382, 0.9263432742809904, 0.875284793939197, 0.8756829014848423]\n",
      "[0.92193125, 0.925125, 0.934875, 0.7746375, 0.78340625]\n"
     ]
    }
   ],
   "source": [
    "predictions_train, aucs_train, accs_train = predict(models, X_train, y_train)\n",
    "print(aucs_train)\n",
    "print(accs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_valid, aucs_val, accs_val = predict(models, X_valid, y_valid)\n",
    "print(aucs_val)\n",
    "print(accs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train.shape, predictions_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hists(predictions, N = 50):\n",
    "    plt.figure(figsize=(20,6))\n",
    "    colors = ['r', 'b', 'y', 'k']\n",
    "    for i in range(predictions.shape[1]):\n",
    "        hist = np.histogram(np.log(predictions[:,i]/(1-predictions[:,i])), N)\n",
    "        # _ = plt.hist(np.log(predictions[:,i]/(1-predictions[:,i])), N, label=str(type(models[i])))\n",
    "        x_axis = np.linspace(hist[1][0], hist[1][-1], N)\n",
    "        plt.plot(x_axis, hist[0]/(hist[1][1]-hist[1][0]), label=str(type(models[i])), c=colors[i])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hists(predictions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hists(predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = 2\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(predictions_valid.shape[1],)))\n",
    "model.add(Dense(hidden_units, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "lr = 1e-4\n",
    "optimizer = adam(lr=lr)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_best_model = 'ensamble_only_train_best_{}_bs_{}_{}.hdf5'.format(lr, batch_size, hidden_units)\n",
    "print(saved_best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(saved_best_model, monitor='val_loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(predictions_train, y_train_cat, \n",
    "          batch_size=batch_size, \n",
    "          epochs=100, \n",
    "          validation_data=(predictions_valid, y_valid_cat), \n",
    "          callbacks = [checkpoint],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('ensamble_only_train_last.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('ensamble_only_train_last.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(saved_best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamble_prediction_train = model.predict(predictions_train, verbose=1)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamble_prediction_train.shape, y_train_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_train, ensamble_prediction_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(np.log(ensamble_prediction_train/(1-ensamble_prediction_train)), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamble_prediction_valid = model.predict(predictions_valid, verbose=1)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(np.log(ensamble_prediction_valid/(1-ensamble_prediction_valid)), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_valid, ensamble_prediction_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr=1e-4 bs=256 roc_auc=0.904051104282362 epocs=50\n",
    "lr=1e-5 bs=256 roc_auc=0.904051104282362 epocs=300\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thres = roc_curve(y_valid, ensamble_prediction_valid)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
