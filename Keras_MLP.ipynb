{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Activation, BatchNormalization, Dropout\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import adam\n",
    "from sklearn.metrics import roc_auc_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_splitted.csv')\n",
    "df_valid = pd.read_csv('valid_splitted.csv')\n",
    "\n",
    "X_train = df_train.drop(columns=['ID_code', 'target']).values\n",
    "X_valid = df_valid.drop(columns=['ID_code', 'target']).values\n",
    "\n",
    "y_train = df_train['target'].values\n",
    "y_valid = df_valid['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160000, 200) (160000,)\n",
      "(40000, 200) (40000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(x,y,t=2):\n",
    "    xs,xn = [],[]\n",
    "    for i in range(t):\n",
    "        x1 = x[y==1].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[:,c][ids]\n",
    "        xs.append(x1)\n",
    "\n",
    "    for i in range(t//2):\n",
    "        x1 = x[y==0].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[:,c][ids]\n",
    "        xn.append(x1)\n",
    "\n",
    "    xs = np.vstack(xs)\n",
    "    xn = np.vstack(xn)\n",
    "    ys = np.ones(xs.shape[0])\n",
    "    yn = np.zeros(xn.shape[0])\n",
    "    x = np.vstack([x,xs,xn])\n",
    "    y = np.concatenate([y,ys,yn])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.89 s, sys: 424 ms, total: 4.32 s\n",
      "Wall time: 1.18 s\n"
     ]
    }
   ],
   "source": [
    "# CPU times: user 13.3 s, sys: 8.3 s, total: 21.6 s\n",
    "# Wall time: 18 s\n",
    "# CPU times: user 3.1 s, sys: 405 ms, total: 3.51 s\n",
    "# Wall time: 1.03 s\n",
    "%time X_train_aug, y_train_aug = augment(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_aug_sqr = X_train_aug\n",
    "X_valid_sqr = X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_aug_sqr = np.append(X_train_aug, X_train_aug**2, axis=1)\n",
    "# X_train_aug_sqr = np.append(X_train_aug_sqr, X_train_aug**3, axis=1)\n",
    "# X_valid_sqr = np.append(X_valid, X_valid**2, axis=1)\n",
    "# X_valid_sqr = np.append(X_valid_sqr, X_valid**3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((336046, 200), (40000, 200))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_aug_sqr.shape, X_valid_sqr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_aug_cat = np.array([y_train_aug, 1-y_train_aug]).T\n",
    "y_valid_cat = np.array([y_valid, 1-y_valid]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model solo con train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l1_reg = l1(l=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 82,402\n",
      "Trainable params: 81,602\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "p_do = 0.5\n",
    "model.add(Dense(200, input_shape=(X_train_aug_sqr.shape[1],))) #kernel_regularizer=l1_reg,\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(p_do))\n",
    "\n",
    "model.add(Dense(200))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(p_do))\n",
    "\n",
    "# model.add(Dense(200))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(p_do))\n",
    "\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from clr import LRFinder\n",
    "\n",
    "# model.compile('SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# batch_size = 256\n",
    "# lr_callback = LRFinder(len(X_train_aug), batch_size,\n",
    "#                        1e-6, 1,\n",
    "#                        # validation_data=(X_val, Y_val),\n",
    "#                        lr_scale='exp', save_dir='data')\n",
    "\n",
    "# # Ensure that number of epochs = 1 when calling fit()\n",
    "# model.fit(X_train_aug, y_train_aug_cat, epochs=1, batch_size=batch_size, callbacks=[lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_callback.plot_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from clr import OneCycleLR\n",
    "\n",
    "# lr_manager = OneCycleLR(1e-2)\n",
    "                        \n",
    "# model.fit(X_train_aug, y_train_aug_cat, \n",
    "#           epochs=10, \n",
    "#           batch_size=batch_size, \n",
    "#           validation_data=(X_test, y_test_cat), \n",
    "#           callbacks=[lr_manager])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('best.hdf5', monitor='val_loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "optimizer = adam(lr=1e-4)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 336046 samples, validate on 40000 samples\n",
      "Epoch 1/50\n",
      "336046/336046 [==============================] - 4s 13us/step - loss: 0.3966 - acc: 0.8483 - val_loss: 0.2828 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.28278, saving model to best.hdf5\n",
      "Epoch 2/50\n",
      "336046/336046 [==============================] - 4s 11us/step - loss: 0.3488 - acc: 0.8636 - val_loss: 0.2805 - val_acc: 0.9061\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.28278 to 0.28046, saving model to best.hdf5\n",
      "Epoch 3/50\n",
      "336046/336046 [==============================] - 4s 12us/step - loss: 0.3308 - acc: 0.8690 - val_loss: 0.2725 - val_acc: 0.9063\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.28046 to 0.27249, saving model to best.hdf5\n",
      "Epoch 4/50\n",
      "336046/336046 [==============================] - 5s 14us/step - loss: 0.3216 - acc: 0.8729 - val_loss: 0.2722 - val_acc: 0.9043\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.27249 to 0.27224, saving model to best.hdf5\n",
      "Epoch 5/50\n",
      "336046/336046 [==============================] - 4s 11us/step - loss: 0.3158 - acc: 0.8743 - val_loss: 0.2676 - val_acc: 0.9058\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.27224 to 0.26762, saving model to best.hdf5\n",
      "Epoch 6/50\n",
      "336046/336046 [==============================] - 4s 13us/step - loss: 0.3115 - acc: 0.8762 - val_loss: 0.2652 - val_acc: 0.9058\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.26762 to 0.26525, saving model to best.hdf5\n",
      "Epoch 7/50\n",
      "336046/336046 [==============================] - 4s 12us/step - loss: 0.3084 - acc: 0.8771 - val_loss: 0.2608 - val_acc: 0.9059\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.26525 to 0.26077, saving model to best.hdf5\n",
      "Epoch 8/50\n",
      "336046/336046 [==============================] - 4s 11us/step - loss: 0.3054 - acc: 0.8777 - val_loss: 0.2572 - val_acc: 0.9051\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.26077 to 0.25723, saving model to best.hdf5\n",
      "Epoch 9/50\n",
      "336046/336046 [==============================] - 4s 11us/step - loss: 0.3035 - acc: 0.8788 - val_loss: 0.2574 - val_acc: 0.9059\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.25723\n",
      "Epoch 10/50\n",
      "336046/336046 [==============================] - 6s 19us/step - loss: 0.3014 - acc: 0.8796 - val_loss: 0.2542 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.25723 to 0.25423, saving model to best.hdf5\n",
      "Epoch 11/50\n",
      "336046/336046 [==============================] - 6s 17us/step - loss: 0.2996 - acc: 0.8801 - val_loss: 0.2545 - val_acc: 0.9068\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.25423\n",
      "Epoch 12/50\n",
      "336046/336046 [==============================] - 4s 12us/step - loss: 0.2980 - acc: 0.8810 - val_loss: 0.2496 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.25423 to 0.24957, saving model to best.hdf5\n",
      "Epoch 13/50\n",
      "336046/336046 [==============================] - 4s 11us/step - loss: 0.2972 - acc: 0.8811 - val_loss: 0.2500 - val_acc: 0.9098\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.24957\n",
      "Epoch 14/50\n",
      "336046/336046 [==============================] - 4s 13us/step - loss: 0.2960 - acc: 0.8812 - val_loss: 0.2463 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.24957 to 0.24625, saving model to best.hdf5\n",
      "Epoch 15/50\n",
      "336046/336046 [==============================] - 5s 14us/step - loss: 0.2949 - acc: 0.8819 - val_loss: 0.2468 - val_acc: 0.9098\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.24625\n",
      "Epoch 16/50\n",
      "336046/336046 [==============================] - 5s 15us/step - loss: 0.2942 - acc: 0.8816 - val_loss: 0.2443 - val_acc: 0.9115\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.24625 to 0.24434, saving model to best.hdf5\n",
      "Epoch 17/50\n",
      "336046/336046 [==============================] - 4s 12us/step - loss: 0.2933 - acc: 0.8823 - val_loss: 0.2432 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.24434 to 0.24317, saving model to best.hdf5\n",
      "Epoch 18/50\n",
      "336046/336046 [==============================] - 4s 13us/step - loss: 0.2920 - acc: 0.8824 - val_loss: 0.2458 - val_acc: 0.9111\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.24317\n",
      "Epoch 19/50\n",
      "336046/336046 [==============================] - 4s 12us/step - loss: 0.2912 - acc: 0.8827 - val_loss: 0.2447 - val_acc: 0.9121\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.24317\n",
      "Epoch 20/50\n",
      "336046/336046 [==============================] - 4s 12us/step - loss: 0.2907 - acc: 0.8832 - val_loss: 0.2461 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.24317\n",
      "Epoch 21/50\n",
      "336046/336046 [==============================] - 4s 11us/step - loss: 0.2906 - acc: 0.8834 - val_loss: 0.2401 - val_acc: 0.9129\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.24317 to 0.24005, saving model to best.hdf5\n",
      "Epoch 22/50\n",
      "336046/336046 [==============================] - 5s 16us/step - loss: 0.2896 - acc: 0.8836 - val_loss: 0.2429 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.24005\n",
      "Epoch 23/50\n",
      "336046/336046 [==============================] - 4s 11us/step - loss: 0.2894 - acc: 0.8833 - val_loss: 0.2433 - val_acc: 0.9116\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.24005\n",
      "Epoch 24/50\n",
      "336046/336046 [==============================] - 4s 11us/step - loss: 0.2889 - acc: 0.8837 - val_loss: 0.2399 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.24005 to 0.23989, saving model to best.hdf5\n",
      "Epoch 25/50\n",
      "336046/336046 [==============================] - 4s 11us/step - loss: 0.2883 - acc: 0.8840 - val_loss: 0.2446 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.23989\n",
      "Epoch 26/50\n",
      "336046/336046 [==============================] - 4s 11us/step - loss: 0.2875 - acc: 0.8841 - val_loss: 0.2391 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.23989 to 0.23906, saving model to best.hdf5\n",
      "Epoch 27/50\n",
      "336046/336046 [==============================] - 4s 13us/step - loss: 0.2868 - acc: 0.8845 - val_loss: 0.2413 - val_acc: 0.9132\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.23906\n",
      "Epoch 28/50\n",
      "336046/336046 [==============================] - 5s 13us/step - loss: 0.2869 - acc: 0.8841 - val_loss: 0.2369 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.23906 to 0.23689, saving model to best.hdf5\n",
      "Epoch 29/50\n",
      "336046/336046 [==============================] - 4s 12us/step - loss: 0.2862 - acc: 0.8845 - val_loss: 0.2411 - val_acc: 0.9132\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.23689\n",
      "Epoch 30/50\n",
      "336046/336046 [==============================] - 4s 11us/step - loss: 0.2860 - acc: 0.8847 - val_loss: 0.2392 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.23689\n",
      "Epoch 31/50\n",
      "336046/336046 [==============================] - 4s 11us/step - loss: 0.2849 - acc: 0.8851 - val_loss: 0.2411 - val_acc: 0.9130\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.23689\n",
      "Epoch 32/50\n",
      "336046/336046 [==============================] - 4s 11us/step - loss: 0.2852 - acc: 0.8852 - val_loss: 0.2394 - val_acc: 0.9138\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.23689\n",
      "Epoch 33/50\n",
      "336046/336046 [==============================] - 4s 12us/step - loss: 0.2850 - acc: 0.8854 - val_loss: 0.2398 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.23689\n",
      "Epoch 34/50\n",
      "336046/336046 [==============================] - 5s 14us/step - loss: 0.2844 - acc: 0.8848 - val_loss: 0.2384 - val_acc: 0.9135\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.23689\n",
      "Epoch 35/50\n",
      "336046/336046 [==============================] - 4s 13us/step - loss: 0.2840 - acc: 0.8858 - val_loss: 0.2364 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.23689 to 0.23636, saving model to best.hdf5\n",
      "Epoch 36/50\n",
      "336046/336046 [==============================] - 4s 11us/step - loss: 0.2838 - acc: 0.8852 - val_loss: 0.2434 - val_acc: 0.9112\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.23636\n",
      "Epoch 37/50\n",
      "336046/336046 [==============================] - 4s 12us/step - loss: 0.2834 - acc: 0.8853 - val_loss: 0.2369 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.23636\n",
      "Epoch 38/50\n",
      "336046/336046 [==============================] - 4s 13us/step - loss: 0.2838 - acc: 0.8853 - val_loss: 0.2358 - val_acc: 0.9152\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.23636 to 0.23582, saving model to best.hdf5\n",
      "Epoch 39/50\n",
      "336046/336046 [==============================] - 4s 11us/step - loss: 0.2833 - acc: 0.8854 - val_loss: 0.2371 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.23582\n",
      "Epoch 40/50\n",
      "336046/336046 [==============================] - 4s 11us/step - loss: 0.2821 - acc: 0.8862 - val_loss: 0.2391 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.23582\n",
      "Epoch 41/50\n",
      "336046/336046 [==============================] - 4s 11us/step - loss: 0.2818 - acc: 0.8862 - val_loss: 0.2391 - val_acc: 0.9138\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.23582\n",
      "Epoch 42/50\n",
      "336046/336046 [==============================] - 4s 13us/step - loss: 0.2816 - acc: 0.8860 - val_loss: 0.2343 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.23582 to 0.23431, saving model to best.hdf5\n",
      "Epoch 43/50\n",
      "336046/336046 [==============================] - 4s 11us/step - loss: 0.2813 - acc: 0.8865 - val_loss: 0.2366 - val_acc: 0.9142\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.23431\n",
      "Epoch 44/50\n",
      "336046/336046 [==============================] - 4s 13us/step - loss: 0.2807 - acc: 0.8865 - val_loss: 0.2391 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.23431\n",
      "Epoch 45/50\n",
      "336046/336046 [==============================] - 4s 13us/step - loss: 0.2809 - acc: 0.8862 - val_loss: 0.2396 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.23431\n",
      "Epoch 46/50\n",
      "336046/336046 [==============================] - 5s 14us/step - loss: 0.2804 - acc: 0.8869 - val_loss: 0.2398 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.23431\n",
      "Epoch 47/50\n",
      "336046/336046 [==============================] - 6s 17us/step - loss: 0.2801 - acc: 0.8867 - val_loss: 0.2410 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.23431\n",
      "Epoch 48/50\n",
      "336046/336046 [==============================] - 4s 11us/step - loss: 0.2800 - acc: 0.8872 - val_loss: 0.2368 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.23431\n",
      "Epoch 49/50\n",
      "336046/336046 [==============================] - 4s 11us/step - loss: 0.2793 - acc: 0.8871 - val_loss: 0.2401 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.23431\n",
      "Epoch 50/50\n",
      "336046/336046 [==============================] - 4s 12us/step - loss: 0.2793 - acc: 0.8870 - val_loss: 0.2354 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.23431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb9012fbd68>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_aug_sqr, y_train_aug_cat, \n",
    "          batch_size=batch_size, \n",
    "          epochs=50, \n",
    "          validation_data=(X_valid_sqr, y_valid_cat), \n",
    "          callbacks = [checkpoint],\n",
    "          verbose=1) \n",
    "          #class_weight=class_weight_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('last_epoch.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('last_epoch.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('MLP_keras_train_only_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336046/336046 [==============================] - 5s 13us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8866904800090115"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train = model.predict(X_train_aug_sqr, verbose=1)\n",
    "roc_auc_score(y_train_aug_cat[:,0], predictions_train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(np.log(predictions_train[:,0]/predictions_train[:,1]), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 1s 14us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8691044805752655"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('last_epoch.hdf5')\n",
    "predictions = model.predict(X_valid_sqr, verbose=1)\n",
    "roc_auc_score(y_valid_cat, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 1s 14us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8688193258969767"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('best.hdf5')\n",
    "predictions = model.predict(X_valid_sqr, verbose=1)\n",
    "roc_auc_score(y_valid_cat, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo todo el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['ID_code', 'target']).values\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.62 s, sys: 495 ms, total: 5.11 s\n",
      "Wall time: 1.56 s\n"
     ]
    }
   ],
   "source": [
    "%time X_aug, y_aug = augment(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_aug_cat = np.array([y_aug, 1-y_aug]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 82,402\n",
      "Trainable params: 81,602\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "p_do = 0.5\n",
    "model.add(Dense(200, input_shape=(X_aug.shape[1],))) #kernel_regularizer=l1_reg,\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(p_do))\n",
    "\n",
    "model.add(Dense(200))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(p_do))\n",
    "\n",
    "# model.add(Dense(200))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(p_do))\n",
    "\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "optimizer = adam(lr=1e-4)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "420098/420098 [==============================] - 5s 12us/step - loss: 0.4779 - acc: 0.8195\n",
      "Epoch 2/20\n",
      "420098/420098 [==============================] - 4s 10us/step - loss: 0.3679 - acc: 0.8568\n",
      "Epoch 3/20\n",
      "420098/420098 [==============================] - 5s 11us/step - loss: 0.3363 - acc: 0.8674\n",
      "Epoch 4/20\n",
      "420098/420098 [==============================] - 5s 11us/step - loss: 0.3225 - acc: 0.8719\n",
      "Epoch 5/20\n",
      "420098/420098 [==============================] - 4s 11us/step - loss: 0.3145 - acc: 0.8748\n",
      "Epoch 6/20\n",
      "420098/420098 [==============================] - 4s 11us/step - loss: 0.3101 - acc: 0.8761\n",
      "Epoch 7/20\n",
      "420098/420098 [==============================] - 5s 12us/step - loss: 0.3065 - acc: 0.8777\n",
      "Epoch 8/20\n",
      "420098/420098 [==============================] - 5s 12us/step - loss: 0.3036 - acc: 0.8788\n",
      "Epoch 9/20\n",
      "420098/420098 [==============================] - 4s 11us/step - loss: 0.3008 - acc: 0.8794\n",
      "Epoch 10/20\n",
      "420098/420098 [==============================] - 4s 11us/step - loss: 0.2997 - acc: 0.8798\n",
      "Epoch 11/20\n",
      "420098/420098 [==============================] - 4s 11us/step - loss: 0.2979 - acc: 0.8805\n",
      "Epoch 12/20\n",
      "420098/420098 [==============================] - 4s 11us/step - loss: 0.2965 - acc: 0.8812\n",
      "Epoch 13/20\n",
      "420098/420098 [==============================] - 4s 11us/step - loss: 0.2953 - acc: 0.8816\n",
      "Epoch 14/20\n",
      "420098/420098 [==============================] - 5s 12us/step - loss: 0.2938 - acc: 0.8819\n",
      "Epoch 15/20\n",
      "420098/420098 [==============================] - 5s 12us/step - loss: 0.2929 - acc: 0.8822\n",
      "Epoch 16/20\n",
      "420098/420098 [==============================] - 5s 12us/step - loss: 0.2923 - acc: 0.8826\n",
      "Epoch 17/20\n",
      "420098/420098 [==============================] - 5s 12us/step - loss: 0.2915 - acc: 0.8830\n",
      "Epoch 18/20\n",
      "420098/420098 [==============================] - 5s 11us/step - loss: 0.2906 - acc: 0.8833\n",
      "Epoch 19/20\n",
      "420098/420098 [==============================] - 4s 11us/step - loss: 0.2902 - acc: 0.8831\n",
      "Epoch 20/20\n",
      "420098/420098 [==============================] - 4s 11us/step - loss: 0.2893 - acc: 0.8842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbc9b588518>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_aug, y_aug_cat, \n",
    "          batch_size=batch_size, \n",
    "          epochs=20, \n",
    "#          callbacks = [checkpoint],\n",
    "          verbose=1) \n",
    "          #class_weight=class_weight_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('MLP_keras_all_data.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv').set_index('ID_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 3s 14us/step\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(df_test.values, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['target'] = test_predictions[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'submission_{}.csv'.format(auc_score)\n",
    "df_test[['target']].to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before_best.hdf5\t   submission_0.8615885372698715.csv\n",
      "best.hdf5\t\t   submission_0.8639528713193811.csv\n",
      "best_orig.hdf5\t\t   submission_0.864849032756072.csv\n",
      "clr.py\t\t\t   test.csv\n",
      "data\t\t\t   test.csv.zip\n",
      "__pycache__\t\t   train.csv\n",
      "sample_submission.csv.zip  train.csv.zip\n",
      "santander_MLP.ipynb\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4.34M/4.34M [00:06<00:00, 751kB/s]\n",
      "Successfully submitted to Santander Customer Transaction Prediction"
     ]
    }
   ],
   "source": [
    "# ! kaggle competitions submit -c santander-customer-transaction-prediction -f {filename} -m \"Second submit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
